{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Features For My Training DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years coached my current coaches for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coaches_years(file_name):\n",
    "    #\"./DataFiles_2018/TeamCoaches.csv\"\n",
    "    df = pd.read_csv(file_name)\n",
    "    years_coached = df[\"CoachName\"].value_counts()\n",
    "    years_coached = pd.DataFrame(years_coached).reset_index()\n",
    "    years_coached.columns = [\"CoachName\", \"years_coached\"]\n",
    "\n",
    "    coachs2018 = df[df[\"Season\"] == 2018].reset_index()\n",
    "    coaches_years = pd.merge(coachs2018, years_coached, on=\"CoachName\", how=\"left\")\n",
    "    coaches_years.drop([\"index\",\"Season\", \"FirstDayNum\", \"LastDayNum\"],axis=1, inplace = True)\n",
    "    return coaches_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coaches_years_2018 = coaches_years(\"./DataFiles_2018/TeamCoaches.csv\")\n",
    "coaches_years_2018.to_csv(\"coaches_years_2018.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Win/Loss record for each team in their conference tournament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Conference_Tourny_WL(Conference_tourny_FP, Team_Conferences_FP):\n",
    "    #\"./DataFiles_2018/ConferenceTourneyGames.csv\", \"./DataFiles_2018/TeamConferences.csv\"\n",
    "    conT_games = pd.read_csv(Conference_tourny_FP)\n",
    "    teamconferences = pd.read_csv(Team_Conferences_FP)\n",
    "    \n",
    "    teamconferences_2018 = teamconferences[teamconferences[\"Season\"] == 2018]\n",
    "    \n",
    "    conT_games_2018 = conT_games[conT_games[\"Season\"] == 2018]\n",
    "    \n",
    "    wins = conT_games_2018[\"WTeamID\"].value_counts()\n",
    "    wins_C_2018 = pd.DataFrame(data = wins).reset_index()\n",
    "    wins_C_2018.columns =[\"TeamID\", \"conference_tourny_wins\"]\n",
    "    \n",
    "    losses = conT_games_2018[\"LTeamID\"].value_counts()\n",
    "    losses_C_2018 = pd.DataFrame(data = losses).reset_index()\n",
    "    losses_C_2018.columns =[\"TeamID\", \"conference_tourny_losses\"]\n",
    "    \n",
    "    conferencesT_WL = reduce(lambda left,right: pd.merge(left,right, on=\"TeamID\", how=\"left\"), [teamconferences_2018, wins_C_2018,losses_C_2018])\n",
    "    conferencesT_WL.fillna(0,inplace=True)\n",
    "    \n",
    "    return conferencesT_WL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conferencest_WL = Conference_Tourny_WL(\"./DataFiles_2018/ConferenceTourneyGames.csv\", \"./DataFiles_2018/TeamConferences.csv\")\n",
    "conferencest_WL.to_csv(\"conference_tourny_WL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a DataFrame that contains every game played in the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def season_games(file_path):\n",
    "    #\"./DataFiles_2018/RegularSeasonCompactResults.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    season_year = df[df[\"Season\"] == 2018]\n",
    "    games = []\n",
    "\n",
    "    for row in season_year.to_dict(\"records\"):\n",
    "        for perspective in [\"W\", \"L\"]:\n",
    "            game = {}\n",
    "            game[\"Won\"] = int(perspective == \"W\")\n",
    "            if perspective == \"W\":\n",
    "                team_letter = \"W\"\n",
    "                opp_letter = \"L\"\n",
    "            else:\n",
    "                team_letter = \"L\"\n",
    "                opp_letter = \"W\"\n",
    "            winner_location = row[\"WLoc\"]\n",
    "            if winner_location == \"A\":\n",
    "                loser_location = \"H\"\n",
    "            elif winner_location == \"H\":\n",
    "                loser_location = \"A\"\n",
    "            else:\n",
    "                loser_location = \"N\"\n",
    "            row[\"LLoc\"] = loser_location\n",
    "            team_stats = [k for k,v in row.items() if k[0] == team_letter]\n",
    "            opp_stats = [k for k,v in row.items() if k[0] == opp_letter]\n",
    "            for stat in team_stats:\n",
    "                game_stat = \"Team\" + stat[1:]\n",
    "                game[game_stat] = row[stat]\n",
    "            for stat in opp_stats:\n",
    "                opp_stat = \"Opp\" + stat[1:]\n",
    "                game[opp_stat] = row[stat]\n",
    "\n",
    "            for general_stat in [\"DayNum\", \"Season\"]:\n",
    "                game[general_stat] = row[general_stat]\n",
    "\n",
    "            games.append(game)\n",
    "    games_year = pd.DataFrame(games)\n",
    "    games_year.drop(['DayNum', 'OppLoc', 'OppScore','Season','TeamLoc','TeamScore'], axis=1, inplace=True)\n",
    "    games_year.rename(columns={\"TeamTeamID\":\"TeamID\"}, inplace=True)\n",
    "    col = [\"TeamID\",\"OppTeamID\",\"Won\"]\n",
    "    games_year = games_year[col]\n",
    "    return games_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games_year = season_games(\"./DataFiles_2018/RegularSeasonCompactResults.csv\")\n",
    "games_year.to_csv(\"games2018.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The season average box score stats for every team. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def team_season_stats(file_path):\n",
    "    #\"./DataFiles_2018/RegularSeasonDetailedResults.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_2018 = df[df[\"Season\"] == 2018]\n",
    "    \n",
    "    games = []\n",
    "    \n",
    "    for row in df_2018.to_dict(\"records\"):\n",
    "        for perspective in [\"W\", \"L\"]:\n",
    "            game = {}\n",
    "            game[\"Win%\"] = int(perspective == \"W\")\n",
    "            if perspective == \"W\":\n",
    "                team_letter = \"W\"\n",
    "                opp_letter = \"L\"\n",
    "            else:\n",
    "                team_letter = \"L\"\n",
    "                opp_letter = \"W\"\n",
    "            winner_location = row[\"WLoc\"]\n",
    "            if winner_location == \"A\":\n",
    "                loser_location = \"H\"\n",
    "            elif winner_location == \"H\":\n",
    "                loser_location = \"A\"\n",
    "            else:\n",
    "                loser_location = \"N\"\n",
    "            row[\"LLoc\"] = loser_location\n",
    "            team_stats = [k for k,v in row.items() if k[0] == team_letter]\n",
    "            for stat in team_stats:\n",
    "                game_stat = stat[1:]\n",
    "                game[game_stat] = row[stat]\n",
    "\n",
    "            for general_stat in [\"DayNum\", \"Season\"]:\n",
    "                game[general_stat] = row[general_stat]\n",
    "            games.append(game)\n",
    "\n",
    "    stats_year = pd.DataFrame(games)\n",
    "    stats_year.drop(\"Loc\", axis=1,inplace=True)\n",
    "    \n",
    "    team_season_stats = pd.DataFrame(columns=['Ast', 'Blk', 'DR', 'FGA', 'FGA3', 'FGM', 'FGM3', 'FTA', 'FTM', 'OR',\n",
    "       'PF', 'Score', 'Stl', 'TO', 'TeamID', \"Win%\"])\n",
    "    \n",
    "    for team in stats_year[\"TeamID\"].unique():\n",
    "        team_stats =stats_year[stats_year[\"TeamID\"] == team]\n",
    "        team_stats_df = pd.DataFrame(team_stats.mean().round(2)).T\n",
    "        team_season_stats = pd.concat([team_season_stats, team_stats_df])\n",
    "    \n",
    "    team_season_stats.reset_index(inplace=True)\n",
    "    return team_season_stats.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_2018_stats = team_season_stats(\"./DataFiles_2018/RegularSeasonDetailedResults.csv\")\n",
    "team_2018_stats.to_csv(\"team_2018_detailed_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the min, average and max ranks for every teams from selected ranking systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ranks(file_path1,file_path2):\n",
    "    #\"./DataFiles_2018/MasseyOrdinals_thruSeason2018_Day128.csv\", \n",
    "    #\"./DataFiles_2018/MasseyOrdinals_2018_133_only_43Systems.csv\"\n",
    "    rankings128 = pd.read_csv(file_path1)\n",
    "    ranking133 = pd.read_csv(file_path2)\n",
    "    rankings = pd.concat([rankings128,ranking133])\n",
    "    rank_2018 = rankings[rankings[\"Season\"] == 2018]\n",
    "    teams = rank_2018[\"TeamID\"].unique()\n",
    "    rank_all = [\"RPI\", \"ESR\", \"EBP\",\"AP\",\"USA\"]\n",
    "    rank_by_team_all = []\n",
    "    for team in teams:\n",
    "        team_rankings = {}\n",
    "        team_rankings[\"TeamID\"] = team\n",
    "        for rank in rank_all:\n",
    "            one_rank = rank_2018[rank_2018[\"SystemName\"] == rank]\n",
    "            team_rank = one_rank[one_rank[\"TeamID\"] == team]\n",
    "            team_rankings[rank+\"_mean\"] = round(team_rank[\"OrdinalRank\"].mean(),2)\n",
    "            team_rankings[rank+\"_min\"] = team_rank[\"OrdinalRank\"].min()\n",
    "            team_rankings[rank+\"_max\"] = team_rank[\"OrdinalRank\"].max()\n",
    "        rank_by_team_all.append(team_rankings)\n",
    "        \n",
    "    all_team_ranks = pd.DataFrame(rank_by_team_all)\n",
    "    all_team_ranks.fillna(35, inplace=True)\n",
    "    return all_team_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the_rankings = get_ranks(\"./DataFiles_2018/MasseyOrdinals_thruSeason2018_Day128.csv\", \"./DataFiles_2018/MasseyOrdinals_2018_133_only_43Systems.csv\")\n",
    "the_rankings.to_csv(\"the_rankings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a DataFrame for every game played in conference tournament. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conf_games(file_path):\n",
    "    #\"./DataFiles_2018/ConferenceTourneyGames.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    season_year = df[df[\"Season\"] == 2018]\n",
    "    games = []\n",
    "\n",
    "    for row in season_year.to_dict(\"records\"):\n",
    "        for perspective in [\"W\", \"L\"]:\n",
    "            game = {}\n",
    "            game[\"Won\"] = int(perspective == \"W\")\n",
    "            if perspective == \"W\":\n",
    "                team_letter = \"W\"\n",
    "                opp_letter = \"L\"\n",
    "            else:\n",
    "                team_letter = \"L\"\n",
    "                opp_letter = \"W\"\n",
    "\n",
    "            team_stats = [k for k,v in row.items() if k[0] == team_letter]\n",
    "            opp_stats = [k for k,v in row.items() if k[0] == opp_letter]\n",
    "            for stat in team_stats:\n",
    "                game_stat = \"Team\" + stat[1:]\n",
    "                game[game_stat] = row[stat]\n",
    "            for stat in opp_stats:\n",
    "                opp_stat = \"Opp\" + stat[1:]\n",
    "                game[opp_stat] = row[stat]\n",
    "\n",
    "            for general_stat in [\"DayNum\", \"Season\"]:\n",
    "                game[general_stat] = row[general_stat]\n",
    "\n",
    "            games.append(game)\n",
    "    games_year = pd.DataFrame(games)\n",
    "    games_year.drop(['DayNum','Season'], axis=1, inplace=True)\n",
    "    games_year.rename(columns={\"TeamTeamID\":\"TeamID\"}, inplace=True)\n",
    "    col = [\"TeamID\",\"OppTeamID\",\"Won\"]\n",
    "    games_year = games_year[col]\n",
    "    return games_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_tourny_games = conf_games(\"./DataFiles_2018/ConferenceTourneyGames.csv\")\n",
    "conf_tourny_games.to_csv(\"conf_tourny_games.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting odds into a usable DataFrame that is able to merge on TeamID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_odds(odds_win, odds_4, all_names_fp, teams_fp):\n",
    "    #\"./DataFiles_2018/Odds_to_wins_tourny.csv\", \"./DataFiles_2018/Odd_to_final4.csv\",\n",
    "    #\"./DataFiles_2018/TeamSpellings.csv\", \"./DataFiles_2018/Teams.csv\"\n",
    "\n",
    "    team_names = pd.read_csv(all_names_fp, encoding=\"latin-1\")\n",
    "    odds_to_win = pd.read_csv(odds_win)\n",
    "    odds_to_final4 = pd.read_csv(odds_4)\n",
    "    all_teams = pd.read_csv(teams_fp)\n",
    "    all_teams.drop([\"FirstD1Season\", \"LastD1Season\"], axis=1, inplace=True)\n",
    "    \n",
    "    odds_to_win[\"odds_to_win\"] = pd.DataFrame(odds_to_win[\"School\"].map(lambda x:x.split(\"+\")[1]))\n",
    "    odds_to_win[\"School\"] = pd.DataFrame(odds_to_win[\"School\"].map(lambda x:x.split(\"+\")[0]))\n",
    "    odds_to_final4[\"odds_to_final4\"] = pd.DataFrame(odds_to_final4[\"School\"].map(lambda x:x.split(\"+\")[1]))\n",
    "    odds_to_final4[\"School\"] = pd.DataFrame(odds_to_final4[\"School\"].map(lambda x:x.split(\"+\")[0]))\n",
    "    \n",
    "    Odds_tourny = pd.merge(odds_to_win,odds_to_final4,on=\"School\")\n",
    "    Odds_tourny[\"School\"] = Odds_tourny[\"School\"].map(lambda x:x.replace(\"\\xa0\", \"\"))\n",
    "    Odds_tourny[\"School\"]= Odds_tourny[\"School\"].map(lambda x:x.lower())\n",
    "    \n",
    "    team_odds = pd.merge(Odds_tourny, team_names, how=\"left\", left_on=\"School\", right_on=\"TeamNameSpelling\")\n",
    "    # four teamid's would still not match up. Had to fill in anyway I could\n",
    "    filler = [1120,1274,1420,1158]\n",
    "    team_odds.loc[team_odds[\"TeamID\"].isnull(), \"TeamID\"] = filler\n",
    "    team_odds.drop([\"School\", \"TeamNameSpelling\"], axis=1, inplace=True)\n",
    "    \n",
    "    all_team_odds = pd.merge(all_teams, team_odds, how=\"left\", on=\"TeamID\")\n",
    "    all_team_odds.fillna(100000, inplace=True)\n",
    "    \n",
    "    return all_team_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_odds = get_odds(\"./DataFiles_2018/Odds_to_wins_tourny.csv\", \"./DataFiles_2018/Odd_to_final4.csv\", \"./DataFiles_2018/TeamSpellings.csv\", \"./DataFiles_2018/Teams.csv\")\n",
    "team_odds.to_csv(\"team_odds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
